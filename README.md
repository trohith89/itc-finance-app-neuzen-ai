---

# ğŸ¤— [ğŸ‘‰Hugging Face Deployed Streamlit App LinkğŸ‘ˆ](https://huggingface.co/spaces/trohith89/ITC-Finance-Analyzer-NeuzenAI)

---

# ğŸ“Š ITC Financial Analyzer APP â€“ AI-Powered Financial Q&A

This interactive AI tool dives into **ITC Ltdâ€™s financial journey**, examining revenues, profitability, and fiscal performance through an intelligent chatbot interface. It fuses **smart web scraping**, **vector embeddings**, and **LLMs** to deliver chat-based, **data-backed answers with transparency**.



## ğŸŒŸ Key Capabilities

- ğŸ¤– **Smart Data Scraper**: Fetches real-time financial disclosures using tools like *Tavily AI*.
- ğŸ§¬ **Embedding Engine**: Transforms scraped text into searchable vectors for high-relevance responses.
- ğŸ—¨ï¸ **Conversational AI**: Ask natural questions, get reliable, structured replies grounded in ITC's actual data.
- ğŸ§‘â€ğŸ’» **Streamlit Interface**: A sleek web app for intuitive financial exploration.

---

## Project Structure

This repository follows a modular structure to separate different components of the project. Below is the breakdown of the project flow:

```bash
itc-financial-analysis/  
â”œâ”€â”€ scraper/              # Tavily scripts for scraping financial data
â”œâ”€â”€ database/             # Used ChromaDB for storing and processing data along with Embeddings
â”œâ”€â”€ embeddings/           # Code for embedding generation and document chunking
â”œâ”€â”€ llm/                  # Code for handling LLM queries and integration
â”œâ”€â”€ app.py                # Streamlit UI for user interaction and Q&A
â””â”€â”€ README.md             # Setup instructions, andÂ usageÂ details
```

## ğŸ“š ITC Report Extractor Module

This backend component scrapes ITC Ltd's official reports and extracts the full text from PDFs using the **Tavily API**. Extracted documents are structured for downstream AI tasks using LangChain.

### ğŸ“Œ Capabilities

- ğŸ”„ Downloads & parses:
  - Annual Reports (2023â€“2024)
  - Quarterly Results (Q1â€“Q4, FY2023â€“FY2025)
  - Consolidated & Standalone Statements
- ğŸ§  Uses `extract_depth="advanced"` for deep content retrieval
- ğŸ—‚ï¸ Adds clean metadata tags for traceability and AI reasoning

### ğŸ§ª Dependencies

```bash
pip install tavily langchain

```
ğŸ§  Embedding Layer with Chroma
This module preps ITC financial content into machine-understandable embeddings using GoogleGenerativeAIEmbeddings and stores them in a Chroma vector database for semantic search.

ğŸ” Functional Highlights
ğŸ“¥ Loads preprocessed LangChain documents (e.g., from pickle files)

âœ‚ï¸ Chunks long documents using RecursiveCharacterTextSplitter

ğŸ§  Embeds using sentence-transformers/all-MiniLM-L6-v2

ğŸ’¾ Persists vectors in a local Chroma DB

ğŸ—œï¸ Zips the DB directory for easier reuse

ğŸ“¦ Install Dependencies

```
pip install langchain chromadb 

from langchain.embeddings import GoogleGenerativeAIEmbeddings

```

ğŸ§  AI-Powered Q&A with Gemini
Engage in deep financial conversations using Google Gemini 2.0 Flash as the LLM. Combined with LangChainâ€™s vector search, it retrieves the most relevant insights from ITCâ€™s disclosures.

ğŸ” Features
ğŸ“‚ Uses MMR (Maximal Marginal Relevance) for sharp and diverse results

ğŸ§¾ Cites source documents for full transparency

ğŸ“Š Tailors answers to metrics, fiscal years, and company context


```
pip install streamlit langchain chromadb langchain-google-genai

```

ğŸ’¬ Streamlit Chat Interface â€“ ITC Analyst
The main app enables interactive Q&A on ITCâ€™s financials via a simple web chat. Responses are generated based on factual transcripts, with full traceability to the original data.

ğŸ¯ Objective
Answer queries about ITCâ€™s earnings, margins, and key performance indicators

Maintain strict alignment with retrieved transcript data

Present year-wise breakdowns and financial facts in clear bullet formats

ğŸ§© Core Tech Stack
ğŸ§± Vector Search (Chroma + MMR) â€“ Pulls relevant context chunks

ğŸ”® LLM Reasoning (Gemini 2.0 Flash) â€“ Converts data to insights

ğŸ§  Chat Memory â€“ Tracks the conversation thread within the session

âš™ï¸ Getting Started
Place the zipped Chroma DB (e.g., CHROMA_DB_BACKUP.zip) in your working directory

Run the Streamlit app (app.py)

Ensure your Google Gemini API key is stored in .streamlit/secrets.toml like this:

```
GOOGLE_API_KEY = "your-api-key-here"

```
streamlit run app.py

```
git clone https://github.com/yourusername/repo-name.git
cd
```




Let me know if youâ€™d like me to help generate a matching `app.py`, `requirements.txt`, or visuals like badges or workflow diagrams!



